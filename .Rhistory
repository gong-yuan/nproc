ind1 = which(ytest==1)
mean(pred$pred.label[ind1]!=ytest[ind1])
fit = glm(y~x,family='binomial')
ypred= predict(fit,xtest)
ypred= predict(fit)
ypred
ypred= predict(fit,type=response)
ypred
mean((ypred>0)!=y)
pred = predict(fit,x)
fit = npc(x, y, method = "svm")
pred = predict(fit,xtest)
pred = predict(fit,x)
pred
pred$pred.label
mean(pred$pred.label!=y)
mean(pred$pred.label==y)
fit = npc(x, y, method = "svm", alpha=0.2)
pred = predict(fit,x)
mean(pred$pred.label==y)
library(nproc)
?npc
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
xtest = matrix(rnorm(n*2),n,2)
ctest = 1+xtest[,1]
ytest = rbinom(n,1,1/(1+exp(-ctest)))
fit = npc(x, y, method = "svm")
pred = predict(fit,xtest)
accuracy = mean(pred$pred.label==ytest)
ind0 = which(ytest==0)
typeI = mean(pred$pred.label[ind0]!=ytest[ind0]) #type I error on test set
typeI
aaccuracy
accuracy
typeI
c = 1-3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
xtest = matrix(rnorm(n*2),n,2)
ctest = 1+xtest[,1]
ytest = rbinom(n,1,1/(1+exp(-ctest)))
fit = npc(x, y, method = "svm")
pred = predict(fit,xtest)
accuracy = mean(pred$pred.label==ytest)
ind0 = which(ytest==0)
typeI = mean(pred$pred.label[ind0]!=ytest[ind0]) #type I error on test set
typeI
accuracy
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
xtest = matrix(rnorm(n*2),n,2)
ctest = 1+3*xtest[,1]
ytest = rbinom(n,1,1/(1+exp(-ctest)))
fit = npc(x, y, method = "svm")
pred = predict(fit,xtest)
accuracy = mean(pred$pred.label==ytest)
ind0 = which(ytest==0)
typeI = mean(pred$pred.label[ind0]!=ytest[ind0]) #type I error on test set
typeI
accuracy
method.list = c('logistic','penlog','svm','randomforest','lda','nb')
for(method in method.list){
cat('method: ', method, '\n')
fit = npc(x, y, method = method)
pred = predict(fit,xtest)
cat('overall error=', mean(pred$pred.label!=ytest), ' ');
ind0 = which(ytest==0)
cat('type I error =', mean(pred$pred.label[ind0]!=ytest[ind0]),'\n');
}
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm")
fit
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm")
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
xtest = matrix(rnorm(n*2),n,2)
ctest = 1+3*xtest[,1]
ytest = rbinom(n,1,1/(1+exp(-ctest)))
fit = npc(x, y, method = "svm")
pred = predict(fit,xtest)
accuracy = mean(pred$pred.label==ytest)
cat("Overall Accuracy: ",  accuracy,'\n')
ind0 = which(ytest==0)
typeI = mean(pred$pred.label[ind0]!=ytest[ind0]) #type I error on test set
cat('Type I error: ', typeI, '\n')
fit = npc(x, y, method = "logistic", alpha = 0.1)
pred = predict(fit,xtest)
accuracy = mean(pred$pred.label==ytest)
cat("Overall Accuracy: ",  accuracy,'\n')
ind0 = which(ytest==0)
typeI = mean(pred$pred.label[ind0]!=ytest[ind0]) #type I error on test set
cat('Type I error: ', typeI, '\n')
library(nproc)
method.list = c('logistic','penlog','svm','randomforest','lda','nb')
for(method in method.list){
cat('method: ', method, '\n')
fit = npc(x, y, method = method)
pred = predict(fit,xtest)
cat('overall error=', mean(pred$pred.label!=ytest), ' ');
ind0 = which(ytest==0)
cat('type I error =', mean(pred$pred.label[ind0]!=ytest[ind0]),'\n');
}
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm")
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm",cv=TRUE)
library(parallel)
?msapplu
?msapply
?mcsapply
?sapplu
?sapply
?mclapply
?sapplu
?sapply
fit = npc(x, y, method = "svm")
percents <- sapply(cutoff.list, FUN=function(cutoff) {
# for every possible cutoff, find the percentage of empirical type I errors > alpha
temp1 = cutoff.bs - cutoff
temp2 = matrix( as.numeric(temp1 > 0), ncol=B )
temp3 = colSums(temp2) / n
apply(outer(temp3,alpha,'>'),2,sum) / B
})
percents2 <- lapply(cutoff.list, FUN=function(cutoff) {
# for every possible cutoff, find the percentage of empirical type I errors > alpha
temp1 = cutoff.bs - cutoff
temp2 = matrix( as.numeric(temp1 > 0), ncol=B )
temp3 = colSums(temp2) / n
apply(outer(temp3,alpha,'>'),2,sum) / B
})
dim(percents)
length(percents)
length(percents2)
percents2
percents
percents2 <- mapply(cutoff.list, FUN=function(cutoff) {
# for every possible cutoff, find the percentage of empirical type I errors > alpha
temp1 = cutoff.bs - cutoff
temp2 = matrix( as.numeric(temp1 > 0), ncol=B )
temp3 = colSums(temp2) / n
apply(outer(temp3,alpha,'>'),2,sum) / B
})
percents2
percents
percents2 <- mcmapply(cutoff.list, FUN=function(cutoff) {
# for every possible cutoff, find the percentage of empirical type I errors > alpha
temp1 = cutoff.bs - cutoff
temp2 = matrix( as.numeric(temp1 > 0), ncol=B )
temp3 = colSums(temp2) / n
apply(outer(temp3,alpha,'>'),2,sum) / B
})
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm")
get.cores()
?mcmapply
MC_CORES
get.cores
?parallels
?parallel
n.cores = detectCores()
n.cores
?mcmapply
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm")
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm", alphalist = seq(from=0.01,to=0.99,by=0.01))
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm", alphalist = seq(from=0,to=1,by=0.01))
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm")
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "logistic")
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
xtest = matrix(rnorm(n*2),n,2)
ctest = 1+3*xtest[,1]
ytest = rbinom(n,1,1/(1+exp(-ctest)))
##Use svm classifier and the default type I error control with alpha=0.05
fit = npc(x, y, method = "svm")
pred = predict(fit,xtest)
accuracy = mean(pred$pred.label==ytest)
cat("Overall Accuracy: ",  accuracy,'\n')
ind0 = which(ytest==0)
typeI = mean(pred$pred.label[ind0]!=ytest[ind0]) #type I error on test set
cat('Type I error: ', typeI, '\n')
####Now, change the method to logistic regression and change alpha to 0.1
fit = npc(x, y, method = "logistic", alpha = 0.1)
pred = predict(fit,xtest)
accuracy = mean(pred$pred.label==ytest)
cat("Overall Accuracy: ",  accuracy,'\n')
ind0 = which(ytest==0)
typeI = mean(pred$pred.label[ind0]!=ytest[ind0]) #type I error on test set
cat('Type I error: ', typeI, '\n')
library(nproc)
library(nproc)
library(nproc)
detectCores()
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
alphalist = seq(from = 0.1, to = 0.9, by = 0.1)
fit = nproc(x, y, method = "svm", alphalist=alphalist)
fit2 = nproc(x, y, method = "svm", alphalist=alphalist, cv = TRUE)
fit3 = nproc(x, y, method = "penlog",n.cores = 2)
fit3 = nproc(x, y, method = "penlog",n.cores = 8)
fit3 = nproc(x, y, method = "penlog")
?mcmapply
library(nproc)
fit3 = nproc(x, y, method = "penlog",  n.cores = 2)
n.cores
n.cores
percents <- sapply(cutoff.list, FUN=function(cutoff) {
# for every possible cutoff, find the percentage of empirical type I errors > alpha
temp1 = cutoff.bs - cutoff
temp2 = matrix( as.numeric(temp1 > 0), ncol=B )
temp3 = colSums(temp2) / n
apply(outer(temp3,alpha,'>'),2,sum) / B
})
cutoff.list
B
percents <- mcmapply(cutoff.list, FUN=function(cutoff) {
# for every possible cutoff, find the percentage of empirical type I errors > alpha
temp1 = cutoff.bs - cutoff
temp2 = matrix( as.numeric(temp1 > 0), ncol=B )
temp3 = colSums(temp2) / n
apply(outer(temp3,alpha,'>'),2,sum) / B
}, mc.cores = 8)
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm",n.cores=2)
n.cores
debug(npc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm",n.cores=2)
n.cores
debug(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm",n.cores=2)
n.cores
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm")
fit2 = nproc(x, y, method = "svm", cv = TRUE)
fit3 = nproc(x, y, method = "penlog",  n.cores = 2)
library(nproc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
fit = nproc(x, y, method = "svm")
fit4 = nproc(x, y, method = "penlog", n.cores = detectCores())
install.packages('e1071')
library(nproc)
?npc
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
xtest = matrix(rnorm(n*2),n,2)
ctest = 1+3*xtest[,1]
ytest = rbinom(n,1,1/(1+exp(-ctest)))
##Use svm classifier and the default type I error control with alpha=0.05
fit = npc(x, y, method = "svm")
fit
?glmnet
?npc
library(nproc)
library(nproc)
library(nproc)
library(nproc)
library(nproc)
library(nproc)
library(nproc)
library(nproc)
89*0/96
89*0.96
95*0.03
setwd("~/Dropbox/Projects/NP-ROC/rpackage/nproc")
setwd("~/Dropbox/teaching/G6101/final/databasebasketball2.1")
team-season = read.table('teams-season.txt')
team-season = read.table('team_season.txt')
team = read.table('team_season.txt')
team
dim(team)
team = read.table('team_season.txt',sep=',')
dim(team)
team[1,]
team = read.table('team_season.txt',sep=',',header=T)
names(team)
team[,which(names(team)='o_dreb')]
team[,which(names(team)=='o_dreb')]
c1 = team[,which(names(team)=='o_dreb')]
c2 = team[,which(names(team)=='d_oreb')]
c1
c2
mean(c1)
mean(c2)
names(team)
o_dreb = team[,which(names(team)=='o_dreb')]
d_oreb = team[,which(names(team)=='d_oreb')]
o_reb = team[,which(names(team)=='o_reb')]
o_reb[1:5]
o_dreb = team[,which(names(team)=='o_dreb')]
d_oreb = team[,which(names(team)=='d_oreb')]
o_reb = team[,which(names(team)=='o_reb')]
ind = 1:5
o_dreb[ind]
d_oreb[ind]
o_reb[ind]
ind = 100:110
o_dreb[ind]
d_oreb[ind]
o_reb[ind]
o_oreb= team[,which(names(team)=='o_oreb')]
o_dreb[ind]
d_oreb[ind]
o_reb[ind]
o_oreb[ind]
d_reb = team[,which(names(team)=='d_reb')]
d_reb[ind]
o_reb[ind]
d_dreb = team[,which(names(team)=='d_dreb')]
ind = 100:110
o_dreb[ind]
d_oreb[ind]
o_reb[ind]
o_oreb[ind]
d_reb[ind]
d_dreb[ind]
o_dreb
ind = 500:510
o_dreb[ind]
d_oreb[ind]
o_reb[ind]
o_oreb[ind]
d_reb[ind]
d_dreb[ind]
mean(o_reb)
mean(d_reb)
mean(o_dreb)
mean(d_oreb)
mean(o_oreb)
mean(d_dreb)
library(nproc)
?nproc
install.packages('ada')
?ada
library(ada)
?ada
data(iris)
##drop setosa
iris[iris$Species!="setosa",]->iris
##set up testing and training data (60% for training)
n<-dim(iris)[1]
trind<-sample(1:n,floor(.6*n),FALSE)
teind<-setdiff(1:n,trind)
iris[,5]<- as.factor((levels(iris[,5])[2:3])[as.numeric(iris[,5])-1])
##fit 8-split trees
gdis<-ada(Species~.,data=iris[trind,],iter=20,nu=1,type="discrete")
gids
gdis
gdis=addtest(gdis,iris[teind,-5],iris[teind,5])
gdis
plot(gdis,TRUE,TRUE)
?svm
library(nproc)
?svm
?npc
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
xtest = matrix(rnorm(n*2),n,2)
ctest = 1+3*xtest[,1]
ytest = rbinom(n,1,1/(1+exp(-ctest)))
##Use svm classifier and the default type I error control with alpha=0.05
fit = npc(x, y, method = "svm")
pred = predict(fit,xtest)
fit.score = predict(fit,x)
accuracy = mean(pred$pred.label==ytest)
cat("Overall Accuracy: ",  accuracy,'\n')
ind0 = which(ytest==0)
typeI = mean(pred$pred.label[ind0]!=ytest[ind0]) #type I error on test set
cat('Type I error: ', typeI, '\n')
##Now, change the method to logistic regression and change alpha to 0.1
fit = npc(x, y, method = "logistic", alpha = 0.1)
pred = predict(fit,xtest)
accuracy = mean(pred$pred.label==ytest)
cat("Overall Accuracy: ",  accuracy,'\n')
ind0 = which(ytest==0)
typeI = mean(pred$pred.label[ind0]!=ytest[ind0]) #type I error on test set
cat('Type I error: ', typeI, '\n')
debug(npc)
n = 1000
x = matrix(rnorm(n*2),n,2)
c = 1+3*x[,1]
y = rbinom(n,1,1/(1+exp(-c)))
xtest = matrix(rnorm(n*2),n,2)
ctest = 1+3*xtest[,1]
ytest = rbinom(n,1,1/(1+exp(-ctest)))
##Use svm classifier and the default type I error control with alpha=0.05
fit = npc(x, y, method = "svm")
pred = predict(fit,xtest)
fit.score = predict(fit,x)
accuracy = mean(pred$pred.label==ytest)
cat("Overall Accuracy: ",  accuracy,'\n')
ind0 = which(ytest==0)
typeI = mean(pred$pred.label[ind0]!=ytest[ind0]) #type I error on test set
cat('Type I error: ', typeI, '\n')
names(fit)
fit$compprob
fit$probA
fit$probB
fit$coefs
dim(train.x)
dim(test.x)
names(fit)
fit$call
fit$type
fit$cost
fit$degree
fit$coef0
fit$coef0
fit$coef
fit$coefs
fit$probA
fit$probB
dim(train.x)
names(fit)
fit$SV
dim(fit$SV)
xtrain[2,]
x.train[2,]
train.x[2,]
summary(fit)
install.packages('ada')
a = rnorm(10)
beta = 1
x = rnorm(10)
prob = 1/(1+exp(-x))
y = rbinom(n,1,prob)
fit = glm(y~x, family='binomial')
n = 50
beta = 1
x = rnorm(n)
prob = 1/(1+exp(-x))
y = rbinom(n,1,prob)
fit = glm(y~x, family='binomial')
summary(fit)
?glm
install.packages("rmarkdown")
devtools::use_vignette("nproc-demo")
